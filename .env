#NGROK_AUTH_TOKEN = '1vikehg18jsR9XrEzKEybCifEr9_AWWFzoCD58Xa151mXfLd'

# Model + Embeddings
MODEL_ID=Qwen/Qwen3-1.7B-Instruct
# Alternative known-small options if needed:
# MODEL_ID=Qwen/Qwen3-1.7B
EMBEDDING_MODEL=BAAI/bge-small-en-v1.5

# Hugging Face access token if required (private models). Leave empty if not needed.
HUGGINGFACE_HUB_TOKEN=

# ChromaDB persistence
CHROMA_DB_DIR=./chroma_db
CHROMA_COLLECTION=wbai_code_knowledge

# Datasets to ingest (comma-separated HF repos).
# Start with small, real datasets. You can add:
# princeton-nlp/SWE-bench_Verified, bigcode/bigcodebench, bigcode/the-stack-v2, livecodebench/code_generation_lite
DATASETS=Muennighoff/mbpp,zai-org/humaneval-x

# Optional dataset configs (key:value comma-separated), for complex datasets
# Example: the-stack-v2:python
DATASET_CONFIG_MAP=

# Sampling to keep ingestion fast. Increase carefully.
MAX_SAMPLES_PER_DATASET=1000
CHUNK_SIZE=1200
CHUNK_OVERLAP=150
TOP_K=5

# API Server
API_KEY=replace-with-a-strong-token
HOST=0.0.0.0
PORT=8000

# Ngrok (public API)
NGROK_AUTH_TOKEN=1vikehg18jsR9XrEzKEybCifEr9_AWWFzoCD58Xa151mXfLd
ENABLE_NGROK=true

# Logging
LOG_LEVEL=INFO
